id: databricks-005
source_url: https://docs.databricks.com/aws/en/clusters/create-cluster
title: Create an All-Purpose Compute Resource in Databricks
platforms:
- Databricks
- AWS
description: This workflow guides users through the process of creating a new all-purpose
  compute resource in Databricks on AWS, including configuration of performance settings
  and basic options.
prerequisites:
- Access to a Databricks workspace with appropriate permissions
- AWS account with sufficient privileges to create compute resources
- Workspace admin access if additional policies or configurations are needed

initial_state:
  catalogs:
    workspace_catalog:
      name: workspace_catalog
      owner: admin
      type: standard
      comment: Default workspace catalog
  schemas:
    workspace_catalog.default:
      catalog_name: workspace_catalog
      schema_name: default
      owner: admin
  tables: {}
  notebooks: {}
  clusters: {}
  jobs: {}
  permissions: []
  active_catalog: null

goal_state:
  catalogs:
    workspace_catalog:
      name: workspace_catalog
      owner: admin
      type: standard
      comment: Default workspace catalog
  schemas:
    workspace_catalog.default:
      catalog_name: workspace_catalog
      schema_name: default
      owner: admin
  tables: {}
  notebooks: {}
  clusters:
    all-purpose-cluster:
      cluster_id: all-purpose-cluster
      name: all-purpose-compute
      state: RUNNING
      node_type: i3.xlarge
      num_workers: 2
      spark_version: "13.3.x-scala2.12"
  jobs: {}
  permissions: []
  active_catalog: null

steps:
- step_id: 1
  description: Navigate to Compute section in Databricks workspace
  method: ui
  sql_command: null
  api_call:
    tool: list_clusters
    parameters: {}
  expected_state_change: {}
  verification:
    check: Verify Compute tab is visible in workspace sidebar

- step_id: 2
  description: Create a new all-purpose compute cluster with default configuration
  method: ui
  sql_command: null
  api_call:
    tool: create_cluster
    parameters:
      name: all-purpose-compute
      node_type: i3.xlarge
      num_workers: 2
      spark_version: "13.3.x-scala2.12"
  expected_state_change:
    clusters:
      all-purpose-cluster:
        cluster_id: all-purpose-cluster
        name: all-purpose-compute
        state: RUNNING
        node_type: i3.xlarge
        num_workers: 2
        spark_version: "13.3.x-scala2.12"
  verification:
    check: Verify compute resource appears in Compute list with status 'Running'

- step_id: 3
  description: Verify compute resource is ready and running
  method: ui
  sql_command: null
  api_call:
    tool: list_clusters
    parameters: {}
  expected_state_change: {}
  verification:
    check: Verify compute status is 'Running' in Compute list
